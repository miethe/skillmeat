#!/usr/bin/env python3
"""
Validate markdown frontmatter against artifact schemas.

Supports legacy artifact types and CCDash-aligned doc_type-driven schemas.
"""

from __future__ import annotations

import argparse
import sys
import warnings
from datetime import date, datetime
from io import StringIO
from pathlib import Path
from typing import Any, Dict, Optional, Tuple, Union
from urllib.parse import unquote, urlparse

import jsonschema
import yaml

warnings.filterwarnings(
    "ignore",
    category=DeprecationWarning,
    message="jsonschema.RefResolver is deprecated.*",
)


SCHEMA_FILENAME_MAP = {
    "progress": "progress.schema.yaml",
    "context": "context.schema.yaml",
    "bug-fix": "bug-fix.schema.yaml",
    "observation": "observation.schema.yaml",
    "prd": "prd.schema.yaml",
    "implementation-plan": "implementation-plan.schema.yaml",
    "phase-plan": "phase-plan.schema.yaml",
    "spike": "spike.schema.yaml",
    "quick-feature": "quick-feature.schema.yaml",
    "report": "report.schema.yaml",
}

ARTIFACT_TYPE_ALIASES = {
    "bug_fix": "bug-fix",
    "bug-fix": "bug-fix",
    "observation": "observation",
    "observations": "observation",
    "implementation": "implementation-plan",
    "implementation-plan": "implementation-plan",
    "implementation_plan": "implementation-plan",
    "phase-plan": "phase-plan",
    "phase_plan": "phase-plan",
    "quick-feature": "quick-feature",
    "quick_feature": "quick-feature",
    "quick-feature-plan": "quick-feature",
    "prd": "prd",
    "progress": "progress",
    "context": "context",
    "spike": "spike",
    "report": "report",
}

DOC_TYPE_TO_ARTIFACT = {
    "progress": "progress",
    "context": "context",
    "bug_fix": "bug-fix",
    "observation": "observation",
    "prd": "prd",
    "implementation_plan": "implementation-plan",
    "phase_plan": "phase-plan",
    "spike": "spike",
    "quick_feature": "quick-feature",
    "report": "report",
}

LEGACY_TYPE_TO_ARTIFACT = {
    "progress": "progress",
    "context": "context",
    "bug-fixes": "bug-fix",
    "observations": "observation",
    "quick-feature-plan": "quick-feature",
}

BASE_STRICT_FIELDS = [
    "schema_version",
    "doc_type",
    "title",
    "status",
    "created",
    "updated",
    "feature_slug",
]

STRICT_FIELDS_BY_TYPE = {
    "implementation-plan": BASE_STRICT_FIELDS + ["prd_ref"],
    "phase-plan": BASE_STRICT_FIELDS + ["phase", "phase_title", "prd_ref", "plan_ref"],
}


def normalize_artifact_type(artifact_type: str) -> Optional[str]:
    """Normalize artifact/doc-type aliases to canonical artifact type names."""
    if not artifact_type:
        return None
    return ARTIFACT_TYPE_ALIASES.get(artifact_type)


def resolve_schema_path(artifact_type: str, schema_dir: Optional[Path] = None) -> Path:
    """Resolve schema file path for an artifact type."""
    canonical = normalize_artifact_type(artifact_type)
    if canonical is None or canonical not in SCHEMA_FILENAME_MAP:
        raise FileNotFoundError(f"Unsupported artifact type: {artifact_type}")

    if schema_dir is None:
        schema_dir = Path(__file__).parent.parent / "schemas"

    schema_path = schema_dir / SCHEMA_FILENAME_MAP[canonical]
    if not schema_path.exists():
        raise FileNotFoundError(f"Schema not found: {schema_path}")
    return schema_path


def load_schema(artifact_type: str, schema_dir: Optional[Path] = None) -> Dict[str, Any]:
    """Load schema for artifact type."""
    schema_path = resolve_schema_path(artifact_type, schema_dir)
    with schema_path.open("r", encoding="utf-8") as handle:
        return yaml.safe_load(handle)


def extract_frontmatter(file_content: str) -> Optional[str]:
    """Extract frontmatter block without delimiters."""
    import re

    if not file_content.startswith("---\n"):
        return None

    match = re.match(r"^---\n(.*?)\n---", file_content, re.DOTALL)
    if not match:
        return None
    return match.group(1)


def parse_frontmatter(frontmatter_str: str) -> Dict[str, Any]:
    """Parse YAML frontmatter into a dictionary."""
    def normalize_yaml_scalars(value: Any) -> Any:
        if isinstance(value, dict):
            return {key: normalize_yaml_scalars(item) for key, item in value.items()}
        if isinstance(value, list):
            return [normalize_yaml_scalars(item) for item in value]
        if isinstance(value, (date, datetime)):
            return value.isoformat()
        return value

    metadata = yaml.safe_load(frontmatter_str)
    if metadata is None:
        return {}
    if not isinstance(metadata, dict):
        raise yaml.YAMLError("Frontmatter must parse to a mapping")
    return normalize_yaml_scalars(metadata)


def detect_artifact_type(metadata: Dict[str, Any]) -> Optional[str]:
    """Detect artifact type from doc_type first, then legacy type field."""
    doc_type = metadata.get("doc_type")
    if isinstance(doc_type, str):
        artifact_type = DOC_TYPE_TO_ARTIFACT.get(doc_type)
        if artifact_type:
            return artifact_type

    legacy_type = metadata.get("type")
    if isinstance(legacy_type, str):
        artifact_type = LEGACY_TYPE_TO_ARTIFACT.get(legacy_type)
        if artifact_type:
            return artifact_type

    return None


def validate_metadata(
    metadata: Dict[str, Any],
    schema: Dict[str, Any],
    schema_path: Optional[Path] = None,
) -> Tuple[bool, list[str]]:
    """Validate metadata against schema, including $ref resolution."""
    errors: list[str] = []

    try:
        validator_cls = jsonschema.validators.validator_for(schema)
        validator_cls.check_schema(schema)

        if schema_path is not None:
            def yaml_file_handler(uri: str) -> Dict[str, Any]:
                parsed = urlparse(uri)
                yaml_path = Path(unquote(parsed.path))
                with yaml_path.open("r", encoding="utf-8") as handle:
                    return yaml.safe_load(handle)

            resolver = jsonschema.RefResolver(
                base_uri=schema_path.resolve().as_uri(),
                referrer=schema,
                handlers={"file": yaml_file_handler},
            )
            validator = validator_cls(schema, resolver=resolver)
        else:
            validator = validator_cls(schema)

        validation_errors = sorted(validator.iter_errors(metadata), key=lambda err: list(err.path))
        if not validation_errors:
            return True, []

        for error in validation_errors:
            path = ".".join(str(part) for part in error.path) if error.path else "root"
            errors.append(f"  [{path}] {error.message}")
        return False, errors

    except Exception as exc:
        errors.append(f"Validation error: {exc}")
        return False, errors


def strict_recommended_field_errors(metadata: Dict[str, Any], artifact_type: str) -> list[str]:
    """Return missing-field errors for strict recommended field validation."""
    fields = STRICT_FIELDS_BY_TYPE.get(artifact_type, BASE_STRICT_FIELDS)
    missing = []
    for field in fields:
        value = metadata.get(field)
        if field not in metadata or value in (None, "", []):
            missing.append(field)

    return [f"  [strict] Missing recommended field: {field}" for field in missing]


def format_validation_report(
    filepath: Union[Path, str],
    artifact_type: str,
    is_valid: bool,
    errors: list[str],
    strict: bool = False,
    metadata: Optional[Dict[str, Any]] = None,
    verbose: bool = False,
) -> str:
    """Format a human-readable validation report."""
    lines = [
        "=" * 70,
        "Artifact Validation Report",
        "=" * 70,
        f"File: {filepath}",
        f"Type: {artifact_type}",
        f"Mode: {'strict' if strict else 'standard'}",
        f"Status: {'✓ VALID' if is_valid else '✗ INVALID'}",
        "=" * 70,
    ]

    if is_valid:
        lines.append("\n✓ All validations passed!")
        if verbose and metadata:
            lines.append("\nMetadata Summary:")
            for field in ["title", "doc_type", "type", "status", "feature_slug", "created", "updated"]:
                if field in metadata:
                    lines.append(f"  {field}: {metadata.get(field)}")
    else:
        lines.append(f"\n✗ Validation failed with {len(errors)} error(s):\n")
        lines.extend(errors)

        lines.append("\nSuggestions:")
        lines.append("  • Check required fields and enum values")
        lines.append("  • Ensure frontmatter parses as valid YAML")
        lines.append("  • Re-run with --verbose for detail")

    lines.append("")
    lines.append("=" * 70)
    return "\n".join(lines)


def validate_artifact_file(
    filepath: Union[Path, str, StringIO],
    artifact_type: Optional[str] = None,
    schema_dir: Optional[Path] = None,
    verbose: bool = False,
    strict: bool = False,
) -> bool:
    """Validate one artifact file or in-memory frontmatter content."""
    try:
        if isinstance(filepath, StringIO):
            content = filepath.getvalue()
            filepath_display: Union[str, Path] = "<StringIO>"
        else:
            file_path = Path(filepath)
            if not file_path.exists():
                print(f"Error: File not found: {file_path}", file=sys.stderr)
                return False
            content = file_path.read_text(encoding="utf-8")
            filepath_display = file_path

        frontmatter_str = extract_frontmatter(content)
        if frontmatter_str is None:
            print(f"Error: No YAML frontmatter found in {filepath_display}", file=sys.stderr)
            return False

        try:
            metadata = parse_frontmatter(frontmatter_str)
        except yaml.YAMLError as exc:
            print(f"Error: Invalid YAML frontmatter in {filepath_display}: {exc}", file=sys.stderr)
            return False

        if artifact_type is not None:
            canonical_type = normalize_artifact_type(artifact_type)
            if canonical_type is None:
                print(f"Error: Unsupported artifact type: {artifact_type}", file=sys.stderr)
                return False
            artifact_type = canonical_type
        else:
            artifact_type = detect_artifact_type(metadata)
            if artifact_type is None:
                print(
                    f"Error: Could not auto-detect artifact type from doc_type/type in {filepath_display}",
                    file=sys.stderr,
                )
                return False

        schema_path = resolve_schema_path(artifact_type, schema_dir)
        schema = load_schema(artifact_type, schema_dir)
        is_valid, errors = validate_metadata(metadata, schema, schema_path)

        if strict:
            errors.extend(strict_recommended_field_errors(metadata, artifact_type))
            if errors:
                is_valid = False

        if verbose or not is_valid:
            print(
                format_validation_report(
                    filepath=filepath_display,
                    artifact_type=artifact_type,
                    is_valid=is_valid,
                    errors=errors,
                    strict=strict,
                    metadata=metadata,
                    verbose=verbose,
                )
            )

        return is_valid

    except FileNotFoundError as exc:
        print(f"Error: {exc}", file=sys.stderr)
        return False
    except Exception as exc:  # pragma: no cover - defensive CLI error path
        print(f"Error validating {filepath}: {exc}", file=sys.stderr)
        return False


def resolve_cli_artifact(args: argparse.Namespace) -> Optional[Path]:
    """Resolve artifact path from --file or positional argument."""
    if args.file and args.artifact:
        print("Error: Use either --file/-f or positional artifact, not both.", file=sys.stderr)
        return None
    if args.file:
        return args.file
    if args.artifact:
        return args.artifact
    print("Error: Missing artifact path. Provide positional path or --file/-f.", file=sys.stderr)
    return None


def main() -> None:
    """CLI entrypoint."""
    parser = argparse.ArgumentParser(
        description="Validate artifact frontmatter against JSON Schema",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python validate_artifact.py path/to/file.md
  python validate_artifact.py -f path/to/file.md --artifact-type prd
  python validate_artifact.py path/to/file.md --strict --verbose
""",
    )

    parser.add_argument("artifact", nargs="?", type=Path, help="Artifact file path")
    parser.add_argument("--file", "-f", type=Path, help="Artifact file path")
    parser.add_argument(
        "--artifact-type",
        "-t",
        choices=sorted(SCHEMA_FILENAME_MAP.keys()),
        help="Explicit artifact type (auto-detected by default)",
    )
    parser.add_argument("--schema-dir", "-s", type=Path, help="Custom schema directory")
    parser.add_argument("--strict", action="store_true", help="Require recommended CCDash fields")
    parser.add_argument("--verbose", "-v", action="store_true", help="Print detailed validation report")

    args = parser.parse_args()
    artifact = resolve_cli_artifact(args)
    if artifact is None:
        sys.exit(1)

    is_valid = validate_artifact_file(
        filepath=artifact,
        artifact_type=args.artifact_type,
        schema_dir=args.schema_dir,
        verbose=args.verbose,
        strict=args.strict,
    )
    sys.exit(0 if is_valid else 1)


if __name__ == "__main__":
    main()
