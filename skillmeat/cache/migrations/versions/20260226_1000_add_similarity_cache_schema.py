"""Add similarity cache schema: fingerprint columns, SimilarityCache table, artifact_fts FTS5

Revision ID: 20260226_1000_add_similarity_cache_schema
Revises: 20260225_1300_add_duplicate_pair_ignored_column
Create Date: 2026-02-26 10:00:00.000000+00:00

Background
----------
Phase 2 of the similarity scoring overhaul (SSO).  Three related schema changes
are bundled into a single migration because they form a cohesive unit — the FTS5
table feeds the text-similarity scorer, and the SimilarityCache stores its output
alongside the other scoring dimensions.

Changes
-------
SSO-2.1  Fingerprint columns on ``collection_artifacts``
    artifact_content_hash  String(64)  nullable  — SHA-256 of artifact file contents
    artifact_structure_hash String(64) nullable  — hash of directory tree shape
    artifact_file_count    Integer     NOT NULL default 0
    artifact_total_size    Integer     NOT NULL default 0

SSO-2.2  New ``similarity_cache`` table
    source_artifact_uuid   String   PK (composite) — FK → artifacts.uuid CASCADE
    target_artifact_uuid   String   PK (composite) — FK → artifacts.uuid CASCADE
    composite_score        Float    NOT NULL
    breakdown_json         Text     nullable
    computed_at            DateTime NOT NULL  default CURRENT_TIMESTAMP

    Index: idx_similarity_cache_source_score (source_artifact_uuid, composite_score)

SSO-2.7  FTS5 virtual table ``artifact_fts``
    Columns: artifact_uuid UNINDEXED, name, title, description, tags
    Tokenizer: porter ascii
    Populated from existing collection_artifacts data at migration time.
    Note: ``title`` is not stored in the artifacts table at this schema version;
    the column is present in the FTS5 table for forward-compatibility and will
    be populated by the scoring engine during its next cache-warm cycle.

    Triggers to keep FTS index in sync:
      artifact_fts_ai  — after INSERT on collection_artifacts
      artifact_fts_ad  — after DELETE on collection_artifacts
      artifact_fts_au  — after UPDATE on collection_artifacts

Rollback
--------
Drops artifact_fts (and its sync triggers), similarity_cache, and the four
fingerprint columns added to collection_artifacts.  Existing similarity data
will be permanently lost; it can be regenerated by re-running the scoring engine.
"""

from __future__ import annotations

import logging
from typing import Sequence, Union

import sqlalchemy as sa
from alembic import op
from sqlalchemy import inspect as sa_inspect

# revision identifiers, used by Alembic.
revision: str = "20260226_1000_add_similarity_cache_schema"
down_revision: Union[str, None] = "20260225_1300_add_duplicate_pair_ignored_column"
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None

logger = logging.getLogger(__name__)

_COLLECTION_ARTIFACTS_TABLE = "collection_artifacts"
_SIMILARITY_CACHE_TABLE = "similarity_cache"
_FTS_TABLE = "artifact_fts"

# Fingerprint columns to add to collection_artifacts (SSO-2.1)
_FINGERPRINT_COLUMNS = [
    sa.Column(
        "artifact_content_hash",
        sa.String(64),
        nullable=True,
        comment=(
            "SHA-256 hash of artifact file contents — "
            "distinct from context-entity content_hash"
        ),
    ),
    sa.Column(
        "artifact_structure_hash",
        sa.String(64),
        nullable=True,
        comment="Hash of artifact directory structure (filenames + tree shape)",
    ),
    sa.Column(
        "artifact_file_count",
        sa.Integer(),
        nullable=False,
        server_default="0",
        comment="Number of files in the artifact",
    ),
    sa.Column(
        "artifact_total_size",
        sa.Integer(),
        nullable=False,
        server_default="0",
        comment="Total byte size of all artifact files",
    ),
]


def upgrade() -> None:
    """Apply all three SSO Phase-2 schema changes.

    Execution order:
    1. Add fingerprint columns to collection_artifacts (batch_alter_table for
       SQLite compatibility — SQLite cannot ADD COLUMN with constraints in one
       ALTER TABLE statement, so batch mode recreates the table safely).
    2. Create the similarity_cache table.
    3. Create the artifact_fts FTS5 virtual table and its sync triggers.
    """
    bind = op.get_bind()
    inspector = sa_inspect(bind)

    # ------------------------------------------------------------------
    # SSO-2.1: Fingerprint columns on collection_artifacts
    # ------------------------------------------------------------------
    existing_cols = {
        col["name"] for col in inspector.get_columns(_COLLECTION_ARTIFACTS_TABLE)
    }

    new_cols = [
        col
        for col in _FINGERPRINT_COLUMNS
        if col.name not in existing_cols  # type: ignore[attr-defined]
    ]

    if new_cols:
        with op.batch_alter_table(_COLLECTION_ARTIFACTS_TABLE) as batch_op:
            for col in new_cols:
                batch_op.add_column(col)
        logger.info(
            "Added fingerprint columns to %s: %s",
            _COLLECTION_ARTIFACTS_TABLE,
            [col.name for col in new_cols],  # type: ignore[attr-defined]
        )
    else:
        logger.info(
            "Fingerprint columns already present on %s — skipping",
            _COLLECTION_ARTIFACTS_TABLE,
        )

    # ------------------------------------------------------------------
    # SSO-2.2: similarity_cache table
    # ------------------------------------------------------------------
    existing_tables = inspector.get_table_names()

    if _SIMILARITY_CACHE_TABLE not in existing_tables:
        op.create_table(
            _SIMILARITY_CACHE_TABLE,
            sa.Column(
                "source_artifact_uuid",
                sa.String(),
                sa.ForeignKey("artifacts.uuid", ondelete="CASCADE"),
                primary_key=True,
                comment="UUID of the source artifact (the 'query' side of the comparison)",
            ),
            sa.Column(
                "target_artifact_uuid",
                sa.String(),
                sa.ForeignKey("artifacts.uuid", ondelete="CASCADE"),
                primary_key=True,
                comment="UUID of the target artifact (the 'candidate' side of the comparison)",
            ),
            sa.Column(
                "composite_score",
                sa.Float(),
                nullable=False,
                comment="Final weighted composite similarity score in [0.0, 1.0]",
            ),
            sa.Column(
                "breakdown_json",
                sa.Text(),
                nullable=True,
                comment="JSON-encoded dict of per-dimension scores (e.g. name, tags, text)",
            ),
            sa.Column(
                "computed_at",
                sa.DateTime(),
                nullable=False,
                server_default=sa.text("CURRENT_TIMESTAMP"),
                comment="Timestamp when this score was computed; used for cache invalidation",
            ),
        )

        op.create_index(
            "idx_similarity_cache_source_score",
            _SIMILARITY_CACHE_TABLE,
            ["source_artifact_uuid", "composite_score"],
        )

        logger.info("Created %s table and index", _SIMILARITY_CACHE_TABLE)
    else:
        logger.info(
            "%s already exists — skipping creation", _SIMILARITY_CACHE_TABLE
        )

    # ------------------------------------------------------------------
    # SSO-2.7: FTS5 virtual table artifact_fts
    # ------------------------------------------------------------------
    _upgrade_fts5()


def _upgrade_fts5() -> None:
    """Create FTS5 virtual table and sync triggers for artifact full-text search.

    Uses a standalone FTS5 table (not external-content mode) so that the index
    is self-contained and does not depend on collection_artifacts row ordering.
    The artifact_uuid column is UNINDEXED — it acts as a join key back to
    collection_artifacts and does not need to participate in text search.

    Falls back gracefully when FTS5 is not compiled into the SQLite installation.
    """
    try:
        op.execute(
            f"""
            CREATE VIRTUAL TABLE IF NOT EXISTS {_FTS_TABLE} USING fts5(
                artifact_uuid UNINDEXED,
                name,
                title,
                description,
                tags,
                tokenize='porter ascii'
            )
            """
        )

        # INSERT trigger — index new artifacts.
        # artifacts.name is the artifact identifier (e.g. "canvas-design").
        # artifacts.description holds the short description.
        # title is NULL here; it can be populated later by the scoring engine
        # once a richer title source is available.
        op.execute(
            f"""
            CREATE TRIGGER IF NOT EXISTS artifact_fts_ai
            AFTER INSERT ON {_COLLECTION_ARTIFACTS_TABLE}
            BEGIN
                INSERT INTO {_FTS_TABLE}(artifact_uuid, name, title, description, tags)
                SELECT
                    NEW.artifact_uuid,
                    a.name,
                    NULL,
                    a.description,
                    NEW.tags_json
                FROM artifacts a
                WHERE a.uuid = NEW.artifact_uuid;
            END
            """
        )

        # DELETE trigger — remove de-indexed artifacts
        op.execute(
            f"""
            CREATE TRIGGER IF NOT EXISTS artifact_fts_ad
            AFTER DELETE ON {_COLLECTION_ARTIFACTS_TABLE}
            BEGIN
                DELETE FROM {_FTS_TABLE}
                WHERE artifact_uuid = OLD.artifact_uuid;
            END
            """
        )

        # UPDATE trigger — re-index on metadata changes
        op.execute(
            f"""
            CREATE TRIGGER IF NOT EXISTS artifact_fts_au
            AFTER UPDATE ON {_COLLECTION_ARTIFACTS_TABLE}
            BEGIN
                DELETE FROM {_FTS_TABLE}
                WHERE artifact_uuid = OLD.artifact_uuid;
                INSERT INTO {_FTS_TABLE}(artifact_uuid, name, title, description, tags)
                SELECT
                    NEW.artifact_uuid,
                    a.name,
                    NULL,
                    a.description,
                    NEW.tags_json
                FROM artifacts a
                WHERE a.uuid = NEW.artifact_uuid;
            END
            """
        )

        # Populate FTS index from existing collection_artifacts data.
        # title is not currently stored in the artifacts table; it will be
        # populated by the scoring engine during its next cache-warm cycle.
        op.execute(
            f"""
            INSERT INTO {_FTS_TABLE}(artifact_uuid, name, title, description, tags)
            SELECT
                ca.artifact_uuid,
                a.name,
                NULL,
                a.description,
                ca.tags_json
            FROM {_COLLECTION_ARTIFACTS_TABLE} ca
            JOIN artifacts a ON a.uuid = ca.artifact_uuid
            """
        )

        logger.info(
            "FTS5 %s virtual table and sync triggers created successfully", _FTS_TABLE
        )

    except Exception as exc:
        error_msg = str(exc).lower()
        if "no such module: fts5" in error_msg or "fts5" in error_msg:
            logger.warning(
                "FTS5 is not available in this SQLite installation. "
                "Artifact full-text search will fall back to LIKE-based queries. "
                "To enable FTS5, SQLite must be compiled with SQLITE_ENABLE_FTS5. "
                "Error: %s",
                exc,
            )
        else:
            raise


def downgrade() -> None:
    """Reverse all SSO Phase-2 schema changes.

    Execution order (reverse of upgrade):
    1. Drop FTS5 virtual table and sync triggers.
    2. Drop similarity_cache table and index.
    3. Remove fingerprint columns from collection_artifacts.

    Warning: all cached similarity scores and FTS index data will be permanently
    lost; they can be regenerated by re-running the scoring engine.
    """
    # ------------------------------------------------------------------
    # SSO-2.7: Drop FTS5 table and triggers
    # ------------------------------------------------------------------
    op.execute("DROP TRIGGER IF EXISTS artifact_fts_au")
    op.execute("DROP TRIGGER IF EXISTS artifact_fts_ad")
    op.execute("DROP TRIGGER IF EXISTS artifact_fts_ai")
    op.execute(f"DROP TABLE IF EXISTS {_FTS_TABLE}")
    logger.info("Dropped %s FTS5 virtual table and triggers", _FTS_TABLE)

    # ------------------------------------------------------------------
    # SSO-2.2: Drop similarity_cache
    # ------------------------------------------------------------------
    bind = op.get_bind()
    inspector = sa_inspect(bind)

    if _SIMILARITY_CACHE_TABLE in inspector.get_table_names():
        op.drop_index(
            "idx_similarity_cache_source_score",
            table_name=_SIMILARITY_CACHE_TABLE,
        )
        op.drop_table(_SIMILARITY_CACHE_TABLE)
        logger.info("Dropped %s table", _SIMILARITY_CACHE_TABLE)

    # ------------------------------------------------------------------
    # SSO-2.1: Remove fingerprint columns from collection_artifacts
    # ------------------------------------------------------------------
    existing_cols = {
        col["name"] for col in inspector.get_columns(_COLLECTION_ARTIFACTS_TABLE)
    }
    fingerprint_col_names = [
        "artifact_content_hash",
        "artifact_structure_hash",
        "artifact_file_count",
        "artifact_total_size",
    ]
    cols_to_drop = [c for c in fingerprint_col_names if c in existing_cols]

    if cols_to_drop:
        with op.batch_alter_table(_COLLECTION_ARTIFACTS_TABLE) as batch_op:
            for col_name in cols_to_drop:
                batch_op.drop_column(col_name)
        logger.info(
            "Dropped fingerprint columns from %s: %s",
            _COLLECTION_ARTIFACTS_TABLE,
            cols_to_drop,
        )
